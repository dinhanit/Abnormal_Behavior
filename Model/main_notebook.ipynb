{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR, CosineAnnealingLR\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "from BaseModel import CustomCNN\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import hyperparameter ###"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 3,
>>>>>>> 76fa3661ef79efd2a02b1ec555c0cf1fcd9fc4ca
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "from BaseModel import CustomCNN\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# Load hyperparameter\n",
    "with open('param.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "for key, value in data.items():\n",
    "    globals()[key] = value\n",
    "    \n",
    "#Load DataSet\n",
    "def LoadData(name=\"\"):\n",
    "    data = np.load(name+\".npz\")\n",
    "    images = data['images']\n",
    "    labels = data['labels']\n",
    "\n",
    "    images = torch.from_numpy(images)\n",
    "    labels = torch.from_numpy(labels)\n",
    "\n",
    "    dataset = TensorDataset(images, labels)\n",
    "    return dataset\n",
    "\n",
    "#Config\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('DEVICE:',DEVICE)\n",
    "model = CustomCNN(num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(DEVICE)\n",
    "criterion.to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=float(LEARNING_RATE))\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=7)\n",
    "\n",
    "TRAINLOADER = DataLoader(LoadData('Data_train'), batch_size=BATCH_SIZE, shuffle=True)\n",
    "TESTLOADER = DataLoader(LoadData('Data_test'), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dinha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss Train: 0.4193 Loss Test: 0.2007 F1 Train: 0.5052 F1 Test: 1.0000\n",
      "Epoch [2/10] Loss Train: 0.0006 Loss Test: 0.0512 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [3/10] Loss Train: 0.0000 Loss Test: 0.0084 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [4/10] Loss Train: 0.0000 Loss Test: 0.0012 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [5/10] Loss Train: 0.0000 Loss Test: 0.0002 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [6/10] Loss Train: 0.0000 Loss Test: 0.0000 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [7/10] Loss Train: 0.0000 Loss Test: 0.0000 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [8/10] Loss Train: 0.0000 Loss Test: 0.0000 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [9/10] Loss Train: 0.0000 Loss Test: 0.0000 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [10/10] Loss Train: 0.0000 Loss Test: 0.0000 F1 Train: 1.0000 F1 Test: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from ConfigModel import *\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "performance= []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    predictions_train = []\n",
    "    true_labels_train = []\n",
    "    \n",
    "    for inputs, labels in TRAINLOADER:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss_train = criterion(outputs, labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss_train.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions_train.extend(predicted.tolist())\n",
    "        true_labels_train.extend(labels.tolist())\n",
    "\n",
    "    train_f1 = f1_score(true_labels_train, predictions_train, average='weighted')\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    model.eval() \n",
    "    total_loss_test = 0.0\n",
    "    total_samples = 0\n",
    "    predictions_test = []\n",
    "    true_labels_test = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in TESTLOADER:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE).long()\n",
    "            outputs = model(inputs)\n",
    "            loss_test = criterion(outputs, labels)\n",
    "            total_loss_test += loss_test.item() * len(labels)\n",
    "            total_samples += len(labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions_test.extend(predicted.tolist())\n",
    "            true_labels_test.extend(labels.tolist())\n",
    "\n",
    "    avg_loss_test = total_loss_test / total_samples\n",
    "    \n",
    "    test_f1 = f1_score(true_labels_test, predictions_test, average='weighted')\n",
    "    \n",
    "    performance.append([running_loss / len(TRAINLOADER),avg_loss_test,train_f1,test_f1])\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss Train: {performance[epoch][0] :.4f} Loss Test: {performance[epoch][1]:.4f} F1 Train: {performance[epoch][2]:.4f} F1 Test: {performance[epoch][3] :.4f}\")\n",
    "\n",
    "#Save Performance\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(performance, columns=['Loss Train', 'Loss Test', 'F1 Train','F1 Test'])\n",
    "df.to_csv('Performance.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset from numpy file and transform to tensor"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": null,
>>>>>>> 76fa3661ef79efd2a02b1ec555c0cf1fcd9fc4ca
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(name=\"\"):\n",
    "    data = np.load(name+\".npz\")\n",
    "    images = data['images']\n",
    "    labels = data['labels']\n",
    "\n",
    "    images = torch.from_numpy(images)\n",
    "    labels = torch.from_numpy(labels)\n",
    "\n",
    "    dataset = TensorDataset(images, labels)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CustomCNN model from BaseModel file"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": null,
>>>>>>> 76fa3661ef79efd2a02b1ec555c0cf1fcd9fc4ca
   "metadata": {},
   "outputs": [],
   "source": [
    "from BaseModel import CustomCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": null,
>>>>>>> 76fa3661ef79efd2a02b1ec555c0cf1fcd9fc4ca
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "#Config\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('DEVICE:',DEVICE)\n",
    "model = CustomCNN(num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(DEVICE)\n",
    "criterion.to(DEVICE)\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=float(LEARNING_RATE))\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=7)\n",
    "\n",
    "TRAINLOADER = DataLoader(LoadData('Data_train'), batch_size=batch_size, shuffle=True)\n",
    "TESTLOADER = DataLoader(LoadData('Data_test'), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": null,
>>>>>>> 76fa3661ef79efd2a02b1ec555c0cf1fcd9fc4ca
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss Train: 0.7217 Loss Test: 0.3287 F1 Train: 0.2793 F1 Test: 1.0000\n",
      "Epoch [2/10] Loss Train: 0.0384 Loss Test: 0.1721 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [3/10] Loss Train: 0.0001 Loss Test: 0.0772 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [4/10] Loss Train: 0.0000 Loss Test: 0.0298 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [5/10] Loss Train: 0.0000 Loss Test: 0.0121 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [6/10] Loss Train: 0.0000 Loss Test: 0.0056 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [7/10] Loss Train: 0.0000 Loss Test: 0.0031 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [8/10] Loss Train: 0.0000 Loss Test: 0.0018 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [9/10] Loss Train: 0.0000 Loss Test: 0.0010 F1 Train: 1.0000 F1 Test: 1.0000\n",
      "Epoch [10/10] Loss Train: 0.0000 Loss Test: 0.0005 F1 Train: 1.0000 F1 Test: 1.0000\n"
     ]
    }
   ],
   "source": [
    "performance= []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    predictions_train = []\n",
    "    true_labels_train = []\n",
    "    \n",
    "    for inputs, labels in TRAINLOADER:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss_train = criterion(outputs, labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss_train.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions_train.extend(predicted.tolist())\n",
    "        true_labels_train.extend(labels.tolist())\n",
    "\n",
    "    train_f1 = f1_score(true_labels_train, predictions_train, average='weighted')\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    model.eval() \n",
    "    total_loss_test = 0.0\n",
    "    total_samples = 0\n",
    "    predictions_test = []\n",
    "    true_labels_test = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in TESTLOADER:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE).long()\n",
    "            outputs = model(inputs)\n",
    "            loss_test = criterion(outputs, labels)\n",
    "            total_loss_test += loss_test.item() * len(labels)\n",
    "            total_samples += len(labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions_test.extend(predicted.tolist())\n",
    "            true_labels_test.extend(labels.tolist())\n",
    "\n",
    "    avg_loss_test = total_loss_test / total_samples\n",
    "    test_f1 = f1_score(true_labels_test, predictions_test, average='weighted')\n",
    "    performance.append([running_loss / len(TRAINLOADER),avg_loss_test,train_f1,test_f1])\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss Train: {performance[epoch][0] :.4f} Loss Test: {performance[epoch][1]:.4f} F1 Train: {performance[epoch][2]:.4f} F1 Test: {performance[epoch][3] :.4f}\")\n",
    "#Save Performance\n",
    "df = pd.DataFrame(performance, columns=['Loss Train', 'Loss Test', 'F1 Train','F1 Test'])\n",
    "df.to_csv('Performance.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
