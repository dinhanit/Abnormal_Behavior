{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR, CosineAnnealingLR\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "from BaseModel import CustomCNN\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import hyperparameter ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\DPL302m\\project\\Abnormal_Behavior\\Model\\param.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for key, value in data.items():\n",
    "    globals()[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset from numpy file and transform to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(name=\"\"):\n",
    "    data = np.load(name+\".npz\")\n",
    "    images = data['images']\n",
    "    labels = data['labels']\n",
    "\n",
    "    images = torch.from_numpy(images)\n",
    "    labels = torch.from_numpy(labels)\n",
    "\n",
    "    dataset = TensorDataset(images, labels)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CustomCNN model from BaseModel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from BaseModel import CustomCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Config\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('DEVICE:',DEVICE)\n",
    "model = CustomCNN(num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(DEVICE)\n",
    "criterion.to(DEVICE)\n",
    "batch_size = BATCH_SIZE\n",
    "EPOCHS = 10\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=float(LEARNING_RATE))\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=7)\n",
    "\n",
    "TRAINLOADER = DataLoader(LoadData('Data_train'), batch_size=batch_size, shuffle=True)\n",
    "TESTLOADER = DataLoader(LoadData('Data_test'), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance= []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    predictions_train = []\n",
    "    true_labels_train = []\n",
    "    \n",
    "    for inputs, labels in TRAINLOADER:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss_train = criterion(outputs, labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss_train.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions_train.extend(predicted.tolist())\n",
    "        true_labels_train.extend(labels.tolist())\n",
    "\n",
    "    train_f1 = f1_score(true_labels_train, predictions_train, average='weighted')\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    model.eval() \n",
    "    total_loss_test = 0.0\n",
    "    total_samples = 0\n",
    "    predictions_test = []\n",
    "    true_labels_test = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in TESTLOADER:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE).long()\n",
    "            outputs = model(inputs)\n",
    "            loss_test = criterion(outputs, labels)\n",
    "            total_loss_test += loss_test.item() * len(labels)\n",
    "            total_samples += len(labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions_test.extend(predicted.tolist())\n",
    "            true_labels_test.extend(labels.tolist())\n",
    "\n",
    "    avg_loss_test = total_loss_test / total_samples\n",
    "    test_f1 = f1_score(true_labels_test, predictions_test, average='weighted')\n",
    "    performance.append([running_loss / len(TRAINLOADER),avg_loss_test,train_f1,test_f1])\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss Train: {performance[epoch][0] :.4f} Loss Test: {performance[epoch][1]:.4f} F1 Train: {performance[epoch][2]:.4f} F1 Test: {performance[epoch][3] :.4f}\")\n",
    "#Save Performance\n",
    "df = pd.DataFrame(performance, columns=['Loss Train', 'Loss Test', 'F1 Train','F1 Test'])\n",
    "df.to_csv('Performance.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
