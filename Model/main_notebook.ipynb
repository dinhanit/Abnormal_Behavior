{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR, CosineAnnealingLR\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from BaseModel import CustomCNN\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\DPL302m\\project\\Abnormal_Behavior\\Model\\param.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for key, value in data.items():\n",
    "    globals()[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(name=\"\"):\n",
    "    data = np.load(name+\".npz\")\n",
    "    images = data['images']\n",
    "    labels = data['labels']\n",
    "\n",
    "    images = torch.from_numpy(images)\n",
    "    labels = torch.from_numpy(labels)\n",
    "\n",
    "    dataset = TensorDataset(images, labels)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Config\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('DEVICE:',DEVICE)\n",
    "model = CustomCNN(num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(DEVICE)\n",
    "criterion.to(DEVICE)\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=float(LEARNING_RATE))\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=7)\n",
    "\n",
    "TRAINLOADER = DataLoader(LoadData('Data_train'), batch_size=batch_size, shuffle=True)\n",
    "TESTLOADER = DataLoader(LoadData('Data_test'), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in TRAINLOADER:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss_train = criterion(outputs,labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for data in TESTLOADER:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE).long()\n",
    "            outputs = model(inputs)\n",
    "            loss_test = criterion(outputs, labels)\n",
    "            \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss Train: {loss_train.item():.4f} Loss Test: {loss_test.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]  - Train Loss: 0.7028 - Train F1: 0.4205 - Test Loss: 0.7071 - Test F1: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]  - Train Loss: 0.7155 - Train F1: 0.6496 - Test Loss: 0.7973 - Test F1: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]  - Train Loss: 1.2143 - Train F1: 0.4423 - Test Loss: 0.6758 - Test F1: 0.5636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]  - Train Loss: 0.1461 - Train F1: 1.0000 - Test Loss: 0.6697 - Test F1: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]  - Train Loss: 0.1556 - Train F1: 0.9614 - Test Loss: 0.6659 - Test F1: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]  - Train Loss: 0.1686 - Train F1: 0.9221 - Test Loss: 0.6598 - Test F1: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]  - Train Loss: 0.1790 - Train F1: 0.9221 - Test Loss: 0.6519 - Test F1: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]  - Train Loss: 0.1023 - Train F1: 1.0000 - Test Loss: 0.6360 - Test F1: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]  - Train Loss: 0.0777 - Train F1: 1.0000 - Test Loss: 0.6030 - Test F1: 0.6190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]  - Train Loss: 0.0512 - Train F1: 1.0000 - Test Loss: 0.5544 - Test F1: 0.8730\n",
      "Finished Training\n",
      "Best model weights saved as best_model_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize variables for early stopping and best model\n",
    "early_stopping_counter = 0\n",
    "best_test_loss = float('inf')\n",
    "best_model_weights = None\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "f1_train = []\n",
    "f1_test = []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    predictions_train = []\n",
    "    true_labels_train = []\n",
    "\n",
    "    for i, data in tqdm(enumerate(TRAINLOADER), desc='train'):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions_train.extend(predicted.tolist())\n",
    "        true_labels_train.extend(labels.tolist())\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()  # Update learning rate with scheduler\n",
    "\n",
    "    train_loss = running_loss / len(TRAINLOADER)\n",
    "    train_f1 = f1_score(true_labels_train, predictions_train, average='weighted')\n",
    "\n",
    "    loss_train.append(train_loss)\n",
    "    f1_train.append(train_f1)\n",
    "\n",
    "    # Evaluation on the test set\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss_val = 0.0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in TESTLOADER:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss_val += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.tolist())\n",
    "            true_labels.extend(labels.tolist())\n",
    "\n",
    "    test_loss_val /= len(TESTLOADER)\n",
    "    test_f1_val = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    loss_test.append(test_loss_val)\n",
    "    f1_test.append(test_f1_val)\n",
    "    print(f'Epoch [{epoch + 1}/{EPOCHS}]  - Train Loss: {train_loss:.4f} - Train F1: {train_f1:.4f} - Test Loss: {test_loss_val:.4f} - Test F1: {test_f1_val:.4f}')\n",
    "\n",
    "    # Check if the test loss has improved\n",
    "    if test_loss_val < best_test_loss:\n",
    "        best_test_loss = test_loss_val\n",
    "        early_stopping_counter = 0\n",
    "        # Save the weights of the best model\n",
    "        best_model_weights = model.state_dict()\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    # Check for early stopping\n",
    "    if early_stopping_counter >= 5:\n",
    "        print(\"Early stopping triggered. No improvement for 5 consecutive epochs.\")\n",
    "        break\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Load the best model weights before saving\n",
    "if best_model_weights is not None:\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "# Save the weights of the best model\n",
    "torch.save(model.state_dict(), 'best_model_weights.pth')\n",
    "print('Best model weights saved as best_model_weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
